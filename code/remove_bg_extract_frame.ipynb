{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_1.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_10.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_100.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_11.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_12.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_13.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_14.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_15.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_16.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_17.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_18.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_19.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_2.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_20.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_21.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_22.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_23.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_24.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_25.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_26.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_27.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_28.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_29.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_3.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_30.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_31.mp4\n",
      "Extracted 51 frames from E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\\hugging\\hugging_32.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m video_filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     38\u001b[0m     video_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_folder, video_filename)\n\u001b[1;32m---> 39\u001b[0m     \u001b[43mextract_frames_with_background_removal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36mextract_frames_with_background_removal\u001b[1;34m(video_path, output_dir, max_frames)\u001b[0m\n\u001b[0;32m     12\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[1;32m---> 16\u001b[0m     fg_mask \u001b[38;5;241m=\u001b[39m \u001b[43mbackground_subtractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     frame_no_bg \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mbitwise_and(frame, frame, mask\u001b[38;5;241m=\u001b[39mfg_mask)\n\u001b[0;32m     20\u001b[0m     output_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(video_path))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def extract_frames_with_background_removal(video_path, output_dir, max_frames=61):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    frame_count = 0\n",
    "\n",
    "    background_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    while cap.isOpened() and frame_count < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret:\n",
    "    \n",
    "            fg_mask = background_subtractor.apply(frame)\n",
    "     \n",
    "            frame_no_bg = cv2.bitwise_and(frame, frame, mask=fg_mask)\n",
    "\n",
    "            output_file = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(video_path))[0]}_{frame_count}.jpg\")\n",
    "            cv2.imwrite(output_file, frame_no_bg)\n",
    "            frame_count += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"Extracted {frame_count} frames from {video_path}\")\n",
    "\n",
    "videos_dir = r\"E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\trim_video\"\n",
    "output_dir = r\"E:\\Drive D\\MA-ICT Convergence\\Thesis\\Human-Human-Interaction\\dataset\\ch4-output-frame-without-bg\\pointing\"\n",
    "\n",
    "for class_name in os.listdir(videos_dir):\n",
    "    class_folder = os.path.join(videos_dir, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        for video_filename in os.listdir(class_folder):\n",
    "            if video_filename.endswith('.mp4'):\n",
    "                video_path = os.path.join(class_folder, video_filename)\n",
    "                extract_frames_with_background_removal(video_path, output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
