{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install filterpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "# Load the pre-trained Faster R-CNN model for human detection\n",
    "try:\n",
    "    net = cv2.dnn.readNetFromTensorflow(r'E:\\Drive D\\MA-ICT Convergence\\Semester 4\\Human-Human-Interaction\\src\\model\\frozen_inference_graph.pb', r'E:\\Drive D\\MA-ICT Convergence\\Semester 4\\Human-Human-Interaction\\src\\model\\graph.pbtxt')\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "\n",
    "# Function to perform human detection\n",
    "def detect_people(frame, net):\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.007843, (frame.shape[1], frame.shape[0]), 127.5)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    boxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            boxes.append((startX, startY, endX, endY))\n",
    "    return boxes\n",
    "\n",
    "# Function to initialize Kalman filters for each detected person\n",
    "def initialize_trackers(boxes):\n",
    "    trackers = []\n",
    "    for box in boxes:\n",
    "        tracker = KalmanFilter(dim_x=4, dim_z=2)\n",
    "        tracker.F = np.array([[1, 0, 1, 0],\n",
    "                               [0, 1, 0, 1],\n",
    "                               [0, 0, 1, 0],\n",
    "                               [0, 0, 0, 1]])\n",
    "        tracker.H = np.array([[1, 0, 0, 0],\n",
    "                               [0, 1, 0, 0]])\n",
    "        tracker.P *= 10\n",
    "        tracker.R = np.array([[5, 0],\n",
    "                               [0, 5]])\n",
    "        tracker.x = np.array([[box[0], box[1], 0, 0]]).T\n",
    "        trackers.append(tracker)\n",
    "    return trackers\n",
    "\n",
    "# Function to update Kalman filters with detected bounding boxes\n",
    "def update_trackers(trackers, boxes):\n",
    "    for tracker, box in zip(trackers, boxes):\n",
    "        tracker.predict()\n",
    "        tracker.update(np.array([[box[0] + (box[2] - box[0]) / 2],\n",
    "                                  [box[1] + (box[3] - box[1]) / 2]]))\n",
    "\n",
    "# Function to assign detections to tracks using the Hungarian algorithm\n",
    "def assign_detections_to_tracks(trackers, boxes):\n",
    "    tracks = np.zeros((len(trackers), 2))\n",
    "    detections = np.zeros((len(boxes), 2))\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        tracks[i] = tracker.x[:2].reshape(2)\n",
    "    for i, box in enumerate(boxes):\n",
    "        detections[i] = np.array([(box[0] + box[2]) / 2, (box[1] + box[3]) / 2])\n",
    "    cost_matrix = np.linalg.norm(tracks[:, None] - detections[None], axis=-1)\n",
    "    tracker_indices, detection_indices = linear_sum_assignment(cost_matrix)\n",
    "    return tracker_indices, detection_indices\n",
    "\n",
    "# Function to perform multiple person tracking\n",
    "def track_people(video_path, output_dir):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    out = cv2.VideoWriter(output_dir, cv2.VideoWriter_fourcc(*'XVID'), fps, (frame_width, frame_height))\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        boxes = detect_people(frame, net)\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            if 'trackers' not in locals():\n",
    "                trackers = initialize_trackers(boxes)\n",
    "            else:\n",
    "                update_trackers(trackers, boxes)\n",
    "                \n",
    "            for tracker in trackers:\n",
    "                (x, y), _ = tracker.update(None)\n",
    "                x, y = int(x), int(y)\n",
    "                cv2.circle(frame, (x, y), 4, (0, 255, 0), -1)\n",
    "        \n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Define the paths for input and output directories\n",
    "input_dir = r'E:\\Drive D\\MA-ICT Convergence\\Semester 4\\Human-Human-Interaction\\dataset\\train'\n",
    "output_dir = r'E:\\Drive D\\MA-ICT Convergence\\Semester 4\\Human-Human-Interaction\\dataset\\output_person_tracking'\n",
    "\n",
    "# Iterate through all video files in the input directory\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.avi'):\n",
    "            video_path = os.path.join(root, file)\n",
    "            track_people(video_path, output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
